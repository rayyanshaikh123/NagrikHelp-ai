services:
  - type: web
    name: local-vision-server
    env: python
    plan: free
    # Use a multi-step build to prefer prebuilt wheels and install torch from
    # the PyTorch wheel index (CPU). This avoids compiling tokenizers/tokenizers
    # from source which is slow and often fails on newer Python/Rust setups.
    buildCommand: |
      python -m pip install --upgrade pip setuptools wheel
  # Install CPU PyTorch wheel first (adjust if you need CUDA). Use
  # --extra-index-url so pip falls back to PyPI for other packages while
  # checking the PyTorch index for the torch wheel.
  pip install --prefer-binary --extra-index-url https://download.pytorch.org/whl/cpu "torch==2.2.0+cpu" || true
      # Now install remaining requirements preferring binary wheels to avoid
      # building native extensions from source when possible.
      pip install --prefer-binary -r local_vision_requirements.txt
    startCommand: uvicorn local_vision_server:app --host 0.0.0.0 --port $PORT
    envVars:
      - key: MODEL_NAME
        value: "microsoft-resnet-500"
      - key: TOP_K
        value: "5"
      # Render provides $PORT at runtime; LOCAL_VISION_HOST is left as default in code
    healthCheckPath: /
