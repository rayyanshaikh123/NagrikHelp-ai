# Local environment variables for development
# Recommended public image classification model names (examples you can use):
# - google/vit-base-patch16-224
# - google/vit-large-patch16-224
# - microsoft/resnet-50
# - facebook/convnext-base-224
# - google/vit-base-patch16-224
# Set MODEL_NAME to one of the above public ids, or a full repo id for private
# models (in which case set HUGGINGFACE_HUB_TOKEN in your environment / Render secrets).
MODEL_NAME=google/vit-base-patch16-224

# How many top labels to return
TOP_K=5

# Local host/port used when running locally (Render will provide $PORT at runtime)
## Bind to all interfaces so other services/containers can reach the server locally.
# For local single-machine development you can also keep 127.0.0.1.
LOCAL_VISION_HOST=0.0.0.0
LOCAL_VISION_PORT=8001

# AI Validation Configuration
# Confidence threshold for issue validation (0.0 to 1.0)
# Recommended: 0.45-0.50 for balanced validation
# Lower (0.35-0.45) = more lenient, accepts borderline cases
# Higher (0.55-0.70) = stricter, only high-confidence images
CONFIDENCE_THRESHOLD=0.45

# Enable/Disable AI models
ENABLE_YOLO=true    # Object detection
ENABLE_CLIP=true    # Zero-shot classification (best accuracy)

# A convenient full URL that the frontend/backend will use when configured.
# Point this at the running local server. When running on the same host use 127.0.0.1.
LOCAL_VISION_URL=http://127.0.0.1:8001

# To run locally (uses the values above):
# python -m uvicorn local_vision_server:app --host $LOCAL_VISION_HOST --port $LOCAL_VISION_PORT
